{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import setGPU\n",
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "import glob\n",
    "import itertools\n",
    "import sys\n",
    "from sklearn.utils import shuffle\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(109984, 100, 3) (109984, 100, 3) (109984, 4) (109984, 4)\n"
     ]
    }
   ],
   "source": [
    "datasets = [np.array([]), np.array([]), np.array([]), np.array([])]\n",
    "dataNames = [\"genJetConstituents\", \"recoJetConstituents\", \"genJetFeatures\", \"recoJetFeatures\"]\n",
    "for fileIN in glob.glob(\"../data/*h5\"):\n",
    "    f = h5py.File(fileIN,\"r\")\n",
    "    for i in range(4):\n",
    "        mydata = f.get(dataNames[i])\n",
    "        datasets[i] = np.concatenate((datasets[i], mydata), axis=0) if datasets[i].size else mydata\n",
    "genJetParticles = datasets[0]\n",
    "recoJetParticles = datasets[1]\n",
    "genJet = datasets[2]\n",
    "recoJet = datasets[3]\n",
    "print(genJetParticles.shape, recoJetParticles.shape, genJet.shape, recoJet.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(109984,)\n"
     ]
    }
   ],
   "source": [
    "# dirty trick: the target is a vector of zeros\n",
    "y = np.zeros(genJetParticles.shape[0])\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(109984, 10)\n",
      "(109984, 14)\n"
     ]
    }
   ],
   "source": [
    "# add the \"noisy\" latent space variables to the genjet dataset\n",
    "rndVars = np.random.normal(0., 1., (genJet.shape[0],10))\n",
    "print(rndVars.shape)\n",
    "genJet = np.concatenate((genJet,rndVars), axis =1)\n",
    "print(genJet.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras imports\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Input, Conv2D, Dropout, Flatten, Concatenate, Reshape, BatchNormalization, Activation, Lambda\n",
    "from keras.layers import AveragePooling2D, Add\n",
    "from keras.utils import plot_model\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, TerminateOnNaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 100, 6, 1)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 100, 6, 1)         4         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 10, 6, 1)          6010      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 10, 6, 1)          4         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 10, 6, 1)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 5, 6, 1)           505       \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 5, 6, 1)           4         \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 5, 6, 1)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 2, 6, 1)           52        \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 2, 6, 1)           4         \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 2, 6, 1)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_relu1 (Dense)          (None, 80)                1040      \n",
      "_________________________________________________________________\n",
      "dense_relu2 (Dense)          (None, 40)                3240      \n",
      "_________________________________________________________________\n",
      "dense_relu3 (Dense)          (None, 20)                820       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 11,704\n",
      "Trainable params: 0\n",
      "Non-trainable params: 11,704\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# import the EMD model\n",
    "from keras.models import model_from_json\n",
    "json_file = open('../models/EMD_Dense_MAE_AsymmetryLarge_1.json')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "emdModel = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "emdModel.load_weights(\"../models/EMD_Dense_MAE_AsymmetryLarge_1.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "for l in emdModel.layers: \n",
    "    l.trainable=False\n",
    "emdModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputGensize = genJet.shape[1]\n",
    "nParticles = genJetParticles.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jet Gen model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the reco jet\n",
    "inputRecoImage = Input(shape=(nParticles,3))\n",
    "xReco = Reshape((100,3,1))(inputRecoImage)\n",
    "\n",
    "# convert the input gen info into an array of \"structured\" noise\n",
    "inputGenJet = Input(shape=(inputGensize,))\n",
    "x = BatchNormalization(name='noise1')(inputGenJet)\n",
    "x = Dense(nParticles, activation=\"relu\",name='noise2')(x)\n",
    "x = Dense(nParticles*3, activation=\"relu\",name='noise3')(x)\n",
    "x = Reshape((nParticles,3),name='noise4')(x)\n",
    "outGen = BatchNormalization(name='noise5')(x)\n",
    "\n",
    "# concatenate the input gen image to the structured noise\n",
    "inputGenImage = Input(shape=(nParticles,3))\n",
    "x = BatchNormalization(name='gen1')(inputGenImage)\n",
    "x = Concatenate(axis=-1,name='gen3')([x,outGen])\n",
    "x = Reshape((nParticles,6,1),name='gen4')(x)\n",
    "\n",
    "# process the image and produce the output\n",
    "\n",
    "x = Conv2D(3, kernel_size=(3,6), strides=(1, 6), data_format=\"channels_last\", padding=\"same\", activation=\"relu\")(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Reshape((100,3))(x)\n",
    "# skip connection\n",
    "x = Add()([x,inputGenImage])\n",
    "x = Reshape((100,3,1))(x)\n",
    "\n",
    "outGen = Reshape((100,3))(x)\n",
    "\n",
    "x = Concatenate(axis=-2)([x,xReco])\n",
    "\n",
    "out = emdModel(x)\n",
    "\n",
    "model = Model(inputs=(inputRecoImage,inputGenJet,inputGenImage), outputs=out)\n",
    "generator = Model(inputs=(inputGenJet,inputGenImage), outputs=outGen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_144 (InputLayer)          (None, 14)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "noise1 (BatchNormalization)     (None, 14)           56          input_144[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "noise2 (Dense)                  (None, 100)          1500        noise1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "noise3 (Dense)                  (None, 300)          30300       noise2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "input_145 (InputLayer)          (None, 100, 3)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "noise4 (Reshape)                (None, 100, 3)       0           noise3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "gen1 (BatchNormalization)       (None, 100, 3)       12          input_145[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "noise5 (BatchNormalization)     (None, 100, 3)       12          noise4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "gen3 (Concatenate)              (None, 100, 6)       0           gen1[0][0]                       \n",
      "                                                                 noise5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "gen4 (Reshape)                  (None, 100, 6, 1)    0           gen3[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 100, 1, 3)    57          gen4[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 100, 1, 3)    0           conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 100, 1, 3)    12          dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_74 (Reshape)            (None, 100, 3)       0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 100, 3)       0           reshape_74[0][0]                 \n",
      "                                                                 input_145[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_143 (InputLayer)          (None, 100, 3)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_75 (Reshape)            (None, 100, 3, 1)    0           add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "reshape_73 (Reshape)            (None, 100, 3, 1)    0           input_143[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 100, 6, 1)    0           reshape_75[0][0]                 \n",
      "                                                                 reshape_73[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 (None, 1)            11704       concatenate_12[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 43,653\n",
      "Trainable params: 31,903\n",
      "Non-trainable params: 11,750\n",
      "__________________________________________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_144 (InputLayer)          (None, 14)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "noise1 (BatchNormalization)     (None, 14)           56          input_144[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "noise2 (Dense)                  (None, 100)          1500        noise1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "noise3 (Dense)                  (None, 300)          30300       noise2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "input_145 (InputLayer)          (None, 100, 3)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "noise4 (Reshape)                (None, 100, 3)       0           noise3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "gen1 (BatchNormalization)       (None, 100, 3)       12          input_145[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "noise5 (BatchNormalization)     (None, 100, 3)       12          noise4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "gen3 (Concatenate)              (None, 100, 6)       0           gen1[0][0]                       \n",
      "                                                                 noise5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "gen4 (Reshape)                  (None, 100, 6, 1)    0           gen3[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 100, 1, 3)    57          gen4[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 100, 1, 3)    0           conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 100, 1, 3)    12          dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_74 (Reshape)            (None, 100, 3)       0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 100, 3)       0           reshape_74[0][0]                 \n",
      "                                                                 input_145[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_75 (Reshape)            (None, 100, 3, 1)    0           add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "reshape_76 (Reshape)            (None, 100, 3)       0           reshape_75[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 31,949\n",
      "Trainable params: 31,903\n",
      "Non-trainable params: 46\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# dirty trick: if the target is a vector of zeros, mae gives the average score (which is what we want)\n",
    "model.compile(optimizer='adam', loss='mae')\n",
    "model.summary()\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 76988 samples, validate on 32996 samples\n",
      "Epoch 1/500\n",
      "76988/76988 [==============================] - 18s 240us/step - loss: 179.3309 - val_loss: 201.7151\n",
      "Epoch 2/500\n",
      "76988/76988 [==============================] - 13s 163us/step - loss: 159.9152 - val_loss: 178.2706\n",
      "Epoch 3/500\n",
      "76988/76988 [==============================] - 12s 161us/step - loss: 147.6054 - val_loss: 157.8411\n",
      "Epoch 4/500\n",
      "76988/76988 [==============================] - 12s 162us/step - loss: 136.8275 - val_loss: 131.0448\n",
      "Epoch 5/500\n",
      "76988/76988 [==============================] - 12s 162us/step - loss: 126.4190 - val_loss: 128.4204\n",
      "Epoch 6/500\n",
      "76988/76988 [==============================] - 12s 162us/step - loss: 120.3703 - val_loss: 128.5358\n",
      "Epoch 7/500\n",
      "76988/76988 [==============================] - 13s 163us/step - loss: 116.3185 - val_loss: 124.1526\n",
      "Epoch 8/500\n",
      "76988/76988 [==============================] - 12s 162us/step - loss: 113.1271 - val_loss: 125.6573\n",
      "Epoch 9/500\n",
      "76988/76988 [==============================] - 13s 163us/step - loss: 110.5010 - val_loss: 118.7982\n",
      "Epoch 10/500\n",
      "76988/76988 [==============================] - 13s 166us/step - loss: 108.1690 - val_loss: 121.6329\n",
      "Epoch 11/500\n",
      "76988/76988 [==============================] - 13s 166us/step - loss: 106.1118 - val_loss: 120.4591\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 12/500\n",
      "76988/76988 [==============================] - 13s 169us/step - loss: 104.8660 - val_loss: 117.8746\n",
      "Epoch 13/500\n",
      "76988/76988 [==============================] - 13s 163us/step - loss: 104.6889 - val_loss: 118.7402\n",
      "Epoch 14/500\n",
      "76988/76988 [==============================] - 13s 164us/step - loss: 104.4892 - val_loss: 118.2927\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 15/500\n",
      "76988/76988 [==============================] - 13s 166us/step - loss: 104.2990 - val_loss: 118.0208\n",
      "Epoch 16/500\n",
      "76988/76988 [==============================] - 13s 170us/step - loss: 104.2783 - val_loss: 117.8646\n",
      "Epoch 17/500\n",
      "76988/76988 [==============================] - 13s 169us/step - loss: 104.2578 - val_loss: 117.8024\n",
      "Epoch 18/500\n",
      "76988/76988 [==============================] - 13s 167us/step - loss: 104.2264 - val_loss: 117.9564\n",
      "Epoch 19/500\n",
      "76988/76988 [==============================] - 13s 164us/step - loss: 104.2144 - val_loss: 117.7920\n",
      "Epoch 20/500\n",
      "76988/76988 [==============================] - 13s 168us/step - loss: 104.1886 - val_loss: 117.5464\n",
      "Epoch 21/500\n",
      "76988/76988 [==============================] - 13s 167us/step - loss: 104.1934 - val_loss: 117.7571\n",
      "Epoch 22/500\n",
      "76988/76988 [==============================] - 13s 164us/step - loss: 104.1347 - val_loss: 117.5861\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 23/500\n",
      "76988/76988 [==============================] - 13s 166us/step - loss: 104.1139 - val_loss: 117.6558\n",
      "Epoch 24/500\n",
      "76988/76988 [==============================] - 12s 162us/step - loss: 104.1339 - val_loss: 117.7788\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 25/500\n",
      "76988/76988 [==============================] - 13s 163us/step - loss: 104.1529 - val_loss: 117.6502\n",
      "Epoch 26/500\n",
      "76988/76988 [==============================] - 13s 167us/step - loss: 104.1078 - val_loss: 117.6285\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 27/500\n",
      "76988/76988 [==============================] - 13s 163us/step - loss: 104.1202 - val_loss: 117.6715\n",
      "Epoch 28/500\n",
      "76988/76988 [==============================] - 13s 165us/step - loss: 104.1463 - val_loss: 117.6955\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 29/500\n",
      "76988/76988 [==============================] - 13s 167us/step - loss: 104.1366 - val_loss: 117.6399\n",
      "Epoch 30/500\n",
      "76988/76988 [==============================] - 13s 166us/step - loss: 104.1376 - val_loss: 117.6428\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "Epoch 00030: early stopping\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "history = model.fit([recoJetParticles, genJet, genJetParticles], y, epochs=500, batch_size=128, verbose = 1,\n",
    "                  validation_split = 0.3, callbacks = [\n",
    "                EarlyStopping(monitor='val_loss', patience=10, verbose=1),\n",
    "                ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, verbose=1),\n",
    "                TerminateOnNaN()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "nameModel = 'JetGen_0'\n",
    "# store history                                                                                                         \n",
    "f = h5py.File(\"../models/%s_history.h5\" %nameModel, \"w\")\n",
    "f.create_dataset(\"training_loss\", data=np.array(history.history['loss']),compression='gzip')\n",
    "f.create_dataset(\"validation_loss\", data=np.array(history.history['val_loss']),compression='gzip')\n",
    "f.close()\n",
    "\n",
    "# store model                                                                                                           \n",
    "model_json = generator.to_json()\n",
    "with open(\"../models/%s_GENERATOR.json\" %nameModel, \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "generator.save_weights(\"../models/%s_GENERATOR.h5\" %nameModel)\n",
    "\n",
    "# store full model                                                                                                           \n",
    "model_json = model.to_json()\n",
    "with open(\"../models/%s.json\" %nameModel, \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(\"../models/%s.h5\" %nameModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
